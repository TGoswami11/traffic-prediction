================================================================================
TRAFFIC VOLUME PREDICTION SYSTEM
Master's Thesis Implementation
================================================================================

Student: Tulsi
University: Technische Hochschule Deggendorf
Program: Master Elektro- und Informationstechnik
Supervisor: Prof. Dr.-Ing. Danny Wauri
Date: January 06, 2026

================================================================================
1. PROJECT OVERVIEW
================================================================================

Objective:
  Develop and compare machine learning models for predicting
  highway traffic volume using BASt data from January 2023.

================================================================================
2. DATA SUMMARY
================================================================================

Dataset: BASt Traffic Counts - January 2023
  - Total Records: 744 hours (31 days)
  - Vehicle Types: PKW (Passenger Cars), LKW (Trucks), Buses
  - Features Engineered: 23 features
    * Temporal: hour, day_of_week, cyclical encodings
    * Lag features: 1h, 2h, 3h, 6h, 12h, 24h, 48h
    * Rolling statistics: 3h, 6h, 12h, 24h windows

Data Split:
  - Training: 21 days (70%) - Jan 1-21
  - Validation: 5 days (15%) - Jan 22-26
  - Test: 5 days (15%) - Jan 27-31

================================================================================
3. MODELS IMPLEMENTED
================================================================================

3.1 XGBoost (Gradient Boosting)
  Parameters:
    - max_depth: 6
    - learning_rate: 0.1
    - n_estimators: 100

3.2 LSTM (Deep Learning)
  Architecture:
    - Hidden size: 64
    - Layers: 1
    - Sequence length: 24 hours
    - Dropout: 0.2

================================================================================
4. RESULTS
================================================================================

Test Set Performance:

  Model      | MAE    | RMSE    | R¬≤      | MAPE
  ------------------------------------------------------------
  XGBoost    | 19.13  | 31.97   | 0.9545  | 22.10%
  LSTM       | 73.72  | 110.74  | -0.3771 | 217.17%

üèÜ Best Model: XGBoost

Performance Improvement:
  - MAE: XGBoost is 54.59 vehicles/hour better (74% improvement)
  - RMSE: XGBoost is 78.77 vehicles/hour better (71% improvement)
  - R¬≤: XGBoost achieves 95.45% accuracy vs LSTM's -37.71%

================================================================================
5. KEY FINDINGS
================================================================================

5.1 Model Performance
  ‚úì XGBoost significantly outperformed LSTM on limited dataset
  ‚úì Traditional ML excels on small tabular datasets (<1000 samples)
  ‚úì Deep learning requires substantially more training data

5.2 Feature Importance (XGBoost)
  ‚úì Lag features (especially 24h, 48h) were most important
  ‚úì Rolling statistics provided valuable trend information
  ‚úì Temporal features captured daily/weekly patterns effectively

5.3 Traffic Patterns Observed
  ‚úì Clear morning (7-9 AM) and evening (5-7 PM) rush hours
  ‚úì Weekday traffic higher than weekend traffic
  ‚úì Night hours (10 PM - 5 AM) show minimal traffic

================================================================================
6. CONCLUSIONS
================================================================================

1. For limited datasets, traditional ML (XGBoost) is superior to
   deep learning approaches (LSTM).

2. Feature engineering is critical for traffic prediction:
   - Lag features capture temporal dependencies
   - Rolling statistics capture trends
   - Cyclical encoding preserves time periodicity

3. XGBoost with MAE of 19.13 vehicles/hour demonstrates
   high accuracy for operational traffic prediction.

4. LSTM underperformance validates the importance of
   sufficient training data for neural networks.

================================================================================
7. FILES GENERATED
================================================================================

Models:
  ‚úì models/xgboost_jan2023.pkl
  ‚úì models/lstm_jan2023.pth

Results:
  ‚úì results/xgboost/xgboost_test_predictions.png
  ‚úì results/xgboost/feature_importance.png
  ‚úì results/lstm/lstm_test_predictions.png
  ‚úì results/lstm/training_history.png
  ‚úì results/comparison/comparison_mae.png
  ‚úì results/comparison/side_by_side_predictions.png

Data:
  ‚úì data/processed/traffic_2023_01_raw.csv
  ‚úì data/processed/traffic_2023_01_clean.csv
  ‚úì data/processed/traffic_2023_01_featured.csv

================================================================================
8. FUTURE WORK
================================================================================

1. Expand dataset to full year for better LSTM performance
2. Implement SARIMA for seasonal baseline comparison
3. Add weather data for improved predictions
4. Test ensemble methods combining XGBoost and LSTM
5. Implement drift detection for model adaptation

================================================================================
END OF REPORT
================================================================================